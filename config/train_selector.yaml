# Model args
model_name_or_path: /public/home/pengxi_lab/project/LLaVA-ReID/Interactive-PEDES_LLaVA-ReID/ # Path to finetuned question model
version: qwen_reid
mm_tunable_parts: mm_selector,mm_language_model
vision_tower: /data/yiding/models/siglip-so400m-patch14-384
mm_vision_select_layer: -2
mm_use_im_patch_token: false
mm_patch_merge_type: spatial_unpad
image_aspect_ratio: pad
mm_projector_type: mlp2x_gelu
image_grid_pinpoints: null


# Data args
data_path: ./Interactive-PEDES_LLaVA-ReID/training_conversations-c4.json
image_folder: /public/share/pengxi_lab/dataset/text-reid
lazy_preprocess: True

# Training args
lora_enable: true
lora_alpha: 256
lora_r: 128
bits: 4
deepspeed: config/deepspeed/zero2_questioner.json

gumbel_temperature: 1.0
gumbel_temperature_end: 0.1
language_model_warm_up_steps: -1

mm_selector_lr: 1.0e-6
bf16: True
run_name: questioner-c4-topk-selector-join
output_dir: ./Interactive-PEDES_LLaVA-ReID/questioner-c4-selector-join
num_train_epochs: 1.0
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
evaluation_strategy: "no"
save_strategy: steps
save_steps: 1000
save_total_limit: 4
learning_rate: 1.0e-6
weight_decay: 0.
warmup_ratio: 0.02
lr_scheduler_type: cosine
logging_steps: 1
tf32: True
model_max_length: 4096
gradient_checkpointing: True
dataloader_num_workers: 1
report_to: none
torch_compile: True
torch_compile_backend: inductor
dataloader_drop_last: True
group_by_modality_length: True
verbose_logging: True
attn_implementation: sdpa
